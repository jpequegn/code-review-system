# Code Review System - Architecture Documentation

Technical architecture and design decisions for the LLM-powered code review system.

## Table of Contents

1. [System Overview](#system-overview)
2. [Component Architecture](#component-architecture)
3. [Data Flow](#data-flow)
4. [Database Schema](#database-schema)
5. [Error Handling](#error-handling)
6. [Security Design](#security-design)
7. [Performance Considerations](#performance-considerations)
8. [Testing Strategy](#testing-strategy)

## System Overview

### High-Level Architecture

```
                    GitHub Event
                         â”‚
                         â–¼
                  Webhook Endpoint
                    (Signature Verify)
                         â”‚
                         â–¼
                   Webhook Handler
                  (Parse & Store Review)
                         â”‚
                         â–¼
                  Review Service
                 (Orchestration)
                    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
                    â–¼         â–¼
            Repository     LLM Analysis
            (Clone & Diff)  (Security + Perf)
                    â”‚         â”‚
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                         â–¼
                   Finding Storage
                         â”‚
                         â–¼
                   GitHub API Client
                    (Post Comments)
                         â”‚
                         â–¼
                   Review Complete
```

### Technology Stack

**Runtime**
- Python 3.11+ (async-capable, type hints)
- FastAPI (modern, async web framework)
- Uvicorn (ASGI server)

**Database**
- SQLAlchemy (ORM for database abstraction)
- SQLite (MVP, file-based)
- PostgreSQL (production option)

**LLM Integration**
- Anthropic SDK (Claude API)
- Requests library (Ollama HTTP API)

**External APIs**
- GitHub API v3 (PR comments, repository info)
- Git command-line (repository operations)

**Testing**
- Pytest (test framework)
- pytest-cov (coverage reporting)
- unittest.mock (mocking)

**Code Quality**
- Black (code formatting)
- Ruff (linting)
- MyPy (type checking, optional)

## Component Architecture

### 1. Webhook Handler (`src/webhooks/github.py`)

**Purpose**: Securely receive and process GitHub webhook events

**Key Classes**
- `GitHubWebhookPayload`: Data class representing PR metadata
- `verify_github_signature()`: Validates HMAC-SHA256 signature
- `parse_github_payload()`: Extracts PR information
- `handle_github_webhook()`: Creates/updates Review records

**Security Measures**
- HMAC-SHA256 signature verification
- Constant-time comparison (`hmac.compare_digest()`)
- Validates required fields before processing
- Supports configurable webhook secret

**Data Flow**
```
Raw Webhook â†’ Signature Verification â†’ Payload Parsing â†’ Database Record
```

**Example**
```python
# Webhook receives:
{
  "action": "opened",
  "pull_request": {
    "number": 42,
    "title": "Fix auth bug",
    "head": {"sha": "abc123", "ref": "feature/auth"},
    "base": {"ref": "main"},
    "user": {"login": "developer"},
    "html_url": "https://github.com/user/repo/pull/42"
  },
  "repository": {
    "full_name": "user/repo",
    "clone_url": "https://github.com/user/repo.git"
  }
}

# Creates Review record:
Review(
  pr_id=42,
  repo_url="https://github.com/user/repo.git",
  branch="feature/auth",
  commit_sha="abc123",
  status=ReviewStatus.PENDING
)
```

### 2. Diff Parser (`src/analysis/diff_parser.py`)

**Purpose**: Parse unified diff format and extract code changes

**Key Classes**
- `FileDiff`: Aggregates all changes for a single file
- `CodeChange`: Represents a single line change
- `DiffParser`: Parses unified diff output

**Algorithm**
1. Split diff into file blocks (lines starting with `@@`)
2. For each file block:
   - Extract file path and change range
   - Parse change lines (preceded by `+`, `-`, or ` `)
   - Group changes with context (lines before/after)
   - Store CodeChange records
3. Filter files:
   - Include: `.py`, `.js`, `.ts`, `.go`, `.java`, `.rb`, etc. (15+ languages)
   - Exclude: test files, `node_modules`, `venv`, documentation

**Capabilities**
- Handles 100+ files in a single diff
- Preserves line numbers for PR comments
- Tracks change context (before/after)
- Handles special characters and Unicode

**Example Output**
```python
FileDiff(
  file_path="app.py",
  language="python",
  additions=5,
  deletions=2,
  changes=[
    CodeChange(
      line_number=42,
      change_type=ChangeType.MODIFIED,
      content="def login(username, password):",
      context_before=["def authenticate():"],
      context_after=["    # Validate credentials"]
    )
  ]
)
```

### 3. Code Analyzer (`src/analysis/analyzer.py`)

**Purpose**: Run security and performance analysis using LLM

**Key Classes**
- `CodeAnalyzer`: Orchestrates analysis
- `AnalyzedFinding`: Represents a single issue
- `FindingCategory`: SECURITY or PERFORMANCE
- `FindingSeverity`: CRITICAL, HIGH, MEDIUM, LOW

**Analysis Process**
1. Convert file diffs to code snippet
2. Send to LLM for security analysis (parallel)
3. Send to LLM for performance analysis (parallel)
4. Parse LLM responses (handle malformed JSON gracefully)
5. Deduplicate findings (by category, file, line, title)
6. Sort by severity
7. Validate findings schema

**Deduplication Strategy**
```
Dedup Key = (category, file_path, line_number, title)

Security finding at line 42: "SQL Injection" â†’ Store
Security finding at line 42: "SQL Injection" â†’ Deduplicated (same key)
Performance finding at line 42: "SQL Injection" â†’ Stored (different category)
```

**LLM Prompts**
- Security: "Analyze for SQL injection, auth flaws, hardcoded secrets, unsafe patterns"
- Performance: "Analyze for algorithm inefficiency, resource leaks, N+1 queries, blocking ops"

**Response Validation**
- Validates JSON schema
- Extracts required fields (title, description, file_path, line_number, severity)
- Gracefully handles missing optional fields
- Continues if parsing fails for single finding

**Example**
```python
AnalyzedFinding(
  category=FindingCategory.SECURITY,
  severity=FindingSeverity.CRITICAL,
  title="SQL Injection Vulnerability",
  description="User input not parameterized in database query",
  file_path="app.py",
  line_number=42,
  suggested_fix="Use parameterized queries: cursor.execute(..., (user_id,))",
  confidence=0.95
)
```

### 4. LLM Providers (`src/llm/`)

**Purpose**: Abstract interface for different LLM backends

**Architecture**
```python
LLMProvider (abstract base class)
  â”œâ”€â”€ ClaudeProvider (Anthropic API)
  â””â”€â”€ OllamaProvider (Local models)
```

**Interface**
```python
class LLMProvider(ABC):
    @abstractmethod
    def analyze_security(self, code_snippet: str) -> dict:
        pass

    @abstractmethod
    def analyze_performance(self, code_snippet: str) -> dict:
        pass
```

**Claude Provider** (`src/llm/claude.py`)
- Uses Anthropic Python SDK
- Streams responses for efficiency
- Implements timeout (30 seconds)
- Handles APITimeoutError and APIError
- Validates response JSON

**Ollama Provider** (`src/llm/ollama.py`)
- Uses HTTP POST to local Ollama instance
- Supports model selection via config
- Implements timeout (60 seconds)
- Retries on transient failures
- Graceful degradation for service unavailable

**Factory Pattern**
```python
def get_llm_provider() -> LLMProvider:
    if settings.llm_provider == "claude":
        return ClaudeProvider()
    elif settings.llm_provider == "ollama":
        return OllamaProvider(settings.ollama_base_url)
    else:
        raise ValueError(f"Unknown LLM provider: {settings.llm_provider}")
```

### 5. GitHub API Client (`src/integrations/github_api.py`)

**Purpose**: Post formatted findings as PR comments

**Key Features**
- Supports HTTPS and SSH repository URLs
- Rate limit handling (detects 403 Forbidden)
- Graceful error handling (404, timeout, network errors)
- Markdown formatting with emojis

**Repository URL Parsing**
```python
# Handles multiple formats
"https://github.com/user/repo.git" â†’ RepositoryInfo("user", "repo")
"git@github.com:user/repo.git" â†’ RepositoryInfo("user", "repo")
"https://github.com/user/repo" â†’ RepositoryInfo("user", "repo")
```

**Comment Formatting**
```markdown
## ğŸ” Code Review Analysis

Found **3** issue(s) in this pull request.

### ğŸ”´ CRITICAL

#### ğŸ›¡ï¸ SQL Injection Vulnerability
**Description:** Unsanitized user input in SQL query
**Location:** `app.py`, line 42

**Suggested Fix:**
```python
# Use parameterized queries
cursor.execute("SELECT * FROM users WHERE id = ?", (user_id,))
```

_Confidence: 95%_

---

### ğŸŸ  HIGH

[more findings...]

_Analysis powered by LLM Code Reviewer_
```

**Severity Emojis**
- ğŸ”´ CRITICAL
- ğŸŸ  HIGH
- ğŸŸ¡ MEDIUM
- ğŸ”µ LOW

**Category Emojis**
- ğŸ›¡ï¸ Security
- âš¡ Performance
- âœ¨ Best Practice

### 6. Review Service (`src/review_service.py`)

**Purpose**: Orchestrate complete analysis pipeline

**Pipeline Steps**
1. Fetch review record from database
2. Update status to ANALYZING
3. Clone repository (shallow, --depth 1)
4. Extract diff between branches
5. Parse diff into code changes
6. Analyze code (security + performance)
7. Store findings in database
8. Post PR comment
9. Update status to COMPLETED
10. Cleanup temporary directory

**Error Handling**
```
Error at any step â†’ Mark FAILED â†’ Log error â†’ Continue (post comment not critical)
```

**Repository Cloning**
```bash
git clone --depth 1 <url> <temp_dir>
# Shallow clone: only latest commit
# --depth 1: ~60x faster for large repos
# Timeout: 60 seconds
```

**Diff Extraction**
```bash
git fetch --all
git diff origin/main...HEAD  # Compare against main branch
# Fallback: git diff main..HEAD (if first format fails)
```

**Cleanup**
- Automatic cleanup of temporary directory
- Uses `shutil.rmtree(ignore_errors=True)` for robustness
- Happens even if analysis fails

**Example Flow**
```python
def process_review(self, review_id: int) -> dict:
    review = self._get_review(review_id)
    self._update_review_status(review, ReviewStatus.ANALYZING)

    repo_path = self._clone_repository(review.repo_url)
    try:
        diff_text = self._extract_diff(repo_path, "main", review.branch)
        file_diffs = self.diff_parser.parse(diff_text)
        findings = self.analyzer.analyze_code_changes(file_diffs)
        finding_records = self._store_findings(review, findings)

        if finding_records:
            self._post_pr_comment(review, findings)

        self._update_review_status(review, ReviewStatus.COMPLETED)

        return {
            "review_id": review_id,
            "status": "completed",
            "findings_count": len(finding_records)
        }
    finally:
        shutil.rmtree(repo_path, ignore_errors=True)
```

### 7. Database Models (`src/database.py`)

**Purpose**: Define data persistence layer

**Models**

**Review**
```python
class Review(Base):
    id: int (primary key)
    pr_id: int (GitHub PR number)
    repo_url: str (repository URL)
    branch: str (feature branch)
    commit_sha: str (commit hash)
    status: ReviewStatus (PENDING, ANALYZING, COMPLETED, FAILED)
    created_at: datetime
    completed_at: datetime (nullable)
    findings: List[Finding] (relationship)
```

**Finding**
```python
class Finding(Base):
    id: int (primary key)
    review_id: int (foreign key â†’ Review)
    category: FindingCategory (SECURITY, PERFORMANCE)
    severity: FindingSeverity (CRITICAL, HIGH, MEDIUM, LOW)
    title: str
    description: str
    file_path: str
    line_number: int (nullable)
    suggested_fix: str (nullable)
    created_at: datetime
```

**Enums**
```python
class ReviewStatus(Enum):
    PENDING = "pending"
    ANALYZING = "analyzing"
    COMPLETED = "completed"
    FAILED = "failed"

class FindingCategory(Enum):
    SECURITY = "security"
    PERFORMANCE = "performance"

class FindingSeverity(Enum):
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
```

**Relationships**
```
Review (1) â”€â”€â†’ (Many) Finding
  via review_id foreign key
  cascade delete: if Review deleted, all Findings deleted
```

## Data Flow

### Request Flow

```
1. GitHub sends webhook
   â”‚
   â”œâ”€ POST /webhook/github
   â”‚ â”œâ”€ Verify signature (HMAC-SHA256)
   â”‚ â”œâ”€ Parse payload
   â”‚ â””â”€ Return 202 Accepted
   â”‚
   â””â”€ (Async processing starts)

2. Webhook Handler
   â”‚
   â”œâ”€ Extract PR metadata
   â”‚ â”œâ”€ pr_id, repo_url, branch, commit_sha
   â”‚ â””â”€ Store in Review table (PENDING)
   â”‚
   â””â”€ (Can return immediately)

3. Review Service (Background)
   â”‚
   â”œâ”€ Update Review status to ANALYZING
   â”‚
   â”œâ”€ Clone Repository
   â”‚ â”œâ”€ git clone --depth 1 <url> <temp>
   â”‚ â””â”€ Timeout: 60 seconds
   â”‚
   â”œâ”€ Extract Diff
   â”‚ â”œâ”€ git diff origin/main...HEAD
   â”‚ â””â”€ Timeout: 30 seconds
   â”‚
   â”œâ”€ Parse Diff
   â”‚ â”œâ”€ Extract file changes
   â”‚ â”œâ”€ Filter files (code only)
   â”‚ â””â”€ Create FileDiff objects
   â”‚
   â”œâ”€ Analyze Code (Parallel)
   â”‚ â”œâ”€ Security Analysis (LLM)
   â”‚ â”‚ â””â”€ Parse response â†’ AnalyzedFinding list
   â”‚ â”‚
   â”‚ â””â”€ Performance Analysis (LLM)
   â”‚     â””â”€ Parse response â†’ AnalyzedFinding list
   â”‚
   â”œâ”€ Deduplicate Findings
   â”‚ â”œâ”€ Group by (category, file, line, title)
   â”‚ â””â”€ Keep highest confidence
   â”‚
   â”œâ”€ Store in Database
   â”‚ â”œâ”€ Create Finding records
   â”‚ â””â”€ Link to Review
   â”‚
   â”œâ”€ Post PR Comment
   â”‚ â”œâ”€ Format findings as markdown
   â”‚ â”œâ”€ Include suggested fixes
   â”‚ â””â”€ (Non-critical: continue if fails)
   â”‚
   â”œâ”€ Update Review status to COMPLETED
   â”‚
   â””â”€ Cleanup
      â””â”€ Delete temporary directory
```

### Database Write Flow

```
GitHub Webhook
    â†“
Create Review (PENDING) â† Fast, immediate response
    â†“
[Background Processing]
    â†“
Create Finding(s) (bulk insert)
    â†“
Update Review (COMPLETED)
```

### Query Patterns

**Get all findings for a review:**
```python
findings = db.query(Finding).filter(Finding.review_id == review_id).all()
```

**Get findings by severity:**
```python
critical = db.query(Finding).filter(
    Finding.review_id == review_id,
    Finding.severity == FindingSeverity.CRITICAL
).all()
```

**Get review history:**
```python
reviews = db.query(Review).filter(
    Review.repo_url == "https://github.com/user/repo.git"
).order_by(Review.created_at.desc()).all()
```

## Database Schema

```sql
-- Reviews table
CREATE TABLE reviews (
  id INTEGER PRIMARY KEY,
  pr_id INTEGER NOT NULL,
  repo_url VARCHAR NOT NULL,
  branch VARCHAR NOT NULL,
  commit_sha VARCHAR NOT NULL,
  status VARCHAR NOT NULL,  -- pending, analyzing, completed, failed
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  completed_at TIMESTAMP NULL
);

-- Findings table
CREATE TABLE findings (
  id INTEGER PRIMARY KEY,
  review_id INTEGER NOT NULL REFERENCES reviews(id) ON DELETE CASCADE,
  category VARCHAR NOT NULL,  -- security, performance
  severity VARCHAR NOT NULL,  -- critical, high, medium, low
  title VARCHAR NOT NULL,
  description TEXT NOT NULL,
  file_path VARCHAR NOT NULL,
  line_number INTEGER NULL,
  suggested_fix TEXT NULL,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Indexes for common queries
CREATE INDEX idx_findings_review_id ON findings(review_id);
CREATE INDEX idx_findings_severity ON findings(severity);
CREATE INDEX idx_reviews_repo_url ON reviews(repo_url);
```

## Error Handling

### Error Categories

**1. Network Errors**
- GitHub webhook delivery failure
- Repository clone timeout (60s)
- LLM API timeout (30s)
- GitHub API rate limiting

**Strategy**: Retry with exponential backoff (future enhancement)

**2. Parsing Errors**
- Malformed GitHub webhook
- Invalid unified diff format
- Malformed LLM response

**Strategy**: Log, skip problematic data, continue

**3. Authorization Errors**
- Invalid GitHub token
- Webhook signature mismatch
- Invalid Claude API key

**Strategy**: Log, fail loudly, don't retry

**4. Database Errors**
- Constraint violations
- Connection pool exhaustion

**Strategy**: Rollback transaction, log error

### Error Recovery

```python
# Example: LLM response handling
try:
    response = json.loads(llm_output)
    validated = self._validate_response(response)
except (json.JSONDecodeError, KeyError) as e:
    logger.warning(f"Malformed LLM response: {e}")
    validated = []  # Continue with empty findings

# Example: Review processing
try:
    # Analysis steps
except Exception as e:
    logger.error(f"Review failed: {e}")
    self._update_review_status(review, ReviewStatus.FAILED)
    # Don't re-raise unless critical
finally:
    # Always cleanup
    shutil.rmtree(repo_path, ignore_errors=True)
```

## Security Design

### Threat Model

**Threats**
1. **Replay Attacks**: Webhook signature verification prevents replay
2. **Tampering**: HMAC-SHA256 detects any payload modification
3. **Unauthorized Access**: GitHub token with minimal permissions
4. **Secret Leakage**: API keys in environment variables, not code/logs
5. **Code Injection**: SQLAlchemy ORM prevents SQL injection

### Mitigations

**Webhook Security**
```python
# Constant-time comparison prevents timing attacks
if not hmac.compare_digest(received_signature, computed_signature):
    raise ValueError("Webhook signature verification failed")
```

**API Key Management**
```python
# Environment variables, never logged
CLAUDE_API_KEY = os.getenv("CLAUDE_API_KEY")
# Never in code or logs
logger.info(f"Analyzed {len(findings)} findings")  # âœ“ Safe
logger.info(f"Using key {api_key[:10]}...")  # âœ— Dangerous
```

**Repository Access**
```python
# Use GitHub token with minimal permissions
# Recommended scopes: repo (private repos only), public_repo
# Avoid: admin, delete_repo
```

**SQL Injection Prevention**
```python
# âœ— Dangerous
db.execute(f"SELECT * FROM reviews WHERE id = {review_id}")

# âœ“ Safe (SQLAlchemy ORM)
db.query(Review).filter(Review.id == review_id).first()
```

### Production Recommendations

1. **Use HTTPS** for webhook communications
2. **Rotate API keys** monthly
3. **Run in VPC** with restricted network access
4. **Monitor** webhook failures and suspicious patterns
5. **Rate limit** webhook processing per repository
6. **Implement authentication** for status/health endpoints
7. **Log security events** (failed signatures, API errors)
8. **Regular security audits** of dependencies

## Performance Considerations

### Bottlenecks

**Repository Operations** (30-40% of total time)
- Clone: 2-5 seconds (network dependent)
- Diff: 1 second
- Optimization: Shallow clone (--depth 1) already used

**LLM Analysis** (40-50% of total time)
- Security analysis: 2-3 seconds
- Performance analysis: 2-3 seconds
- Parallel execution already used

**Database Operations** (10% of total time)
- Insert review: <10ms
- Insert findings: 50-100ms (bulk operation)
- Minimal optimization needed

### Benchmarks

```
Typical PR with 10 files:
- Clone: 2s
- Diff: 0.5s
- Security analysis: 2.5s
- Performance analysis: 2.5s
- Database: 0.1s
- Post comment: 0.5s
Total: ~8.5 seconds

Large PR with 50 files:
- Clone: 2s
- Diff: 1s
- Security analysis: 4s
- Performance analysis: 4s
- Database: 0.2s
- Post comment: 0.5s
Total: ~11.7 seconds
```

### Optimization Strategies

**Future Enhancements**
1. **Code snippet caching**: Cache analysis results for similar patterns
2. **Concurrent analysis**: Use asyncio for parallel operations
3. **Batch mode**: Process multiple PRs in single LLM call
4. **Incremental analysis**: Only analyze changed code sections
5. **Model caching**: Keep model in memory (Ollama)

## Testing Strategy

### Test Organization

**Unit Tests** (200+ tests)
- Component-level testing
- Mock external dependencies
- Fast execution (<1 second)
- High coverage (90%+)

**Integration Tests** (25+ tests)
- End-to-end workflows
- Real database (SQLite)
- Mock external APIs
- Moderate execution (10-50ms)

**Test Coverage**
```
src/analysis/analyzer.py: 87% (highest-value targets missing)
src/analysis/diff_parser.py: 94%
src/config.py: 98%
src/database.py: 89%
src/integrations/github_api.py: 99%
src/llm/claude.py: 100%
src/llm/ollama.py: 96%
src/llm/provider.py: 95%
src/main.py: 33% (mostly endpoints)
src/review_service.py: 93%
src/webhooks/github.py: 100%

TOTAL: 91%
```

### Mock Strategy

**LLM Providers**
```python
# Mock responses to avoid API costs
@patch("src.llm.claude.Anthropic")
def test_claude_provider(mock_api):
    mock_api.return_value.messages.create.return_value = {
        "content": [{"text": '{"findings": [...]}'}]
    }
```

**GitHub API**
```python
# Mock GitHub responses
@patch("requests.post")
def test_post_comment(mock_post):
    mock_post.return_value.status_code = 201
    mock_post.return_value.json.return_value = {"id": 123}
```

**Database**
```python
# Use in-memory SQLite for tests
DATABASE_URL = "sqlite:///:memory:"
```

### Critical Test Paths

1. **Webhook signature verification**
2. **Diff parsing with edge cases**
3. **Finding deduplication**
4. **LLM response parsing**
5. **End-to-end review processing**
6. **Database constraints**
7. **Error recovery**

---

**For more information**, see:
- [README.md](README.md) - Quick start and overview
- [USAGE_GUIDE.md](USAGE_GUIDE.md) - Practical examples
- Implementation Plan (docs/plans/)
